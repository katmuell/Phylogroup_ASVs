---
title: "Baumgartner DADA2"
output: html_document
---

#Load Libraries
```{r}
library(readr)
library(fs)
library(dplyr)
library(tibble)
library(Biostrings)
library(dada2)
library(stringr)
library(magrittr)
library(ggplot2)
library(tidyr)
library(phyloseq)
```

#Setup
Set up paths and directories
```{r}
#Directories
data.dir = "/work/kdm65"
demux.dir = "/work/kdm65/baumgartner"
output.dir = "/work/kdm65/scratch"

#Files
map.file = file.path(data.dir, "baumgartner_map.txt")
silva.ref = file.path(data.dir, "silva_nr99_v138.1_wSpecies_train_set.fa.gz")
ps.rds = file.path(output.dir, "baumgartner.rds")
```

#Filter and Trim
Get lists of forward and reverse reads
```{r}
fnFs <- sort(list.files(demux.dir, pattern = "_1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(demux.dir, pattern = "_2.fastq.gz", full.names = TRUE))

forward_fastq_suffix = "_1.fastq.gz"

fnFs %>%
  basename %>%
  str_replace(forward_fastq_suffix,"") ->
  sample.names
```

```{r}
print(fnFs)
```

```{r}
print(fnRs)
```

```{r}
print(sample.names)
```

#Quality Profiles
```{r}
plotQualityProfile(fnFs[1:2])
```

```{r}
plotQualityProfile(fnRs[1:2])
```

#Fitler Reads
Assign filepaths for filtered files
```{r}
filt_path <- file.path(output.dir, "filtered")
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq.gz"))
```

Filter reads
```{r}
filt.out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, trimLeft = 10, truncLen = c(240, 200),
                          maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE,
                          compress = TRUE, multithread = FALSE)
```

```{r}
head(filt.out)
```

Remove files that didn't pass filtering
```{r}
filtFs = filtFs[file_exists(filtFs)]
filtRs = filtRs[file_exists(filtRs)]
```


#Learn Error Rates
```{r}
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
```

```{r}
plotErrors(errF, nominalQ = TRUE)
```

#Dereplication
```{r}
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
```

```{r}
derepFs %>%
  names %>%
  str_replace("_F_filt.fastq.gz","") ->
  sample.names
```


```{r}
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```

#Sample Inference
```{r}
dadaFs <- dada(derepFs, err=errF, multithread = TRUE)
dadaRs <- dada(derepRs, err=errR, multithread = TRUE)
```

```{r}
dadaFs[[2]]
```

#Merge Paired Reads
```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)
```

```{r}
head(mergers[[2]])
```

#Further Processing
Construct sequence table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
table(nchar(getSequences(seqtab)))
```

```{r}
seqtab2 <- seqtab[, nchar(colnames(seqtab)) %in% seq(380,408)]
```

Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab2, method = "consensus", multithread = TRUE, verbose = TRUE)
dim(seqtab.nochim)
```

```{r}
sum(seqtab.nochim)/sum(seqtab2)
```

Track reads through the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
filt.out %>%
  as_tibble(rownames = "filename") %>%
  mutate(sample = str_replace(filename, forward_fastq_suffix, "")) %>%
  select(sample, input = reads.in, filtered = reads.out) ->
  track

sapply(dadaFs, getN) %>%
  enframe(name = "sample", value = "denoised") ->
  denoised
track %<>% full_join(denoised, by = c("sample"))

sapply(mergers, getN) %>%
  enframe(name = "sample", value = "merged") ->
  merged
track %<>% full_join(merged, by = c("sample"))

rowSums(seqtab2) %>%
  enframe(name = "sample", value = "tabled") ->
  tabled
track %<>% full_join(tabled, by = c("sample"))

rowSums(seqtab.nochim) %>%
  enframe(name = "sample", value = "nonchim") ->
  nonchim
track %<>% full_join(nonchim, by = c("sample"))

track
```

```{r}
track %>%
  gather(key = "stage", value = "counts", -c("sample")) %>%
  replace_na(list(counts = 0)) %>%
  mutate(stage=factor(stage, levels = c('input', 'filtered', 'denoised', 'merged', 'tabled', 'nonchim'))) %>%
  ggplot(mapping = aes(x = stage, y = counts, by = sample, group = sample)) + geom_line(alpha = 0.05) + theme_classic()
```

#Assign Taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, silva.ref, multithread = TRUE)
taxa.print <- taxa
rownames(taxa.print) <- NULL
head(taxa.print)
```

#Make Phyloseq Object
Load metadata
```{r}
metadata.df = read_csv(map.file) %>%
  dplyr::rename(Sample = "Run") %>%
  column_to_rownames("Sample") %>%
  as.data.frame()

metadata.df
```

Construct phyloseq object
```{r}
otus = otu_table(seqtab.nochim, taxa_are_rows = FALSE)
sd = sample_data(metadata.df)
ps <- phyloseq(otus, sd, tax_table(taxa))

ps
```

Save phyloseq object as RDS
```{r}
write_rds(ps, ps.rds)
```

Confirm that the RDS is usable
```{r}
loaded.ps = read_rds(ps.rds)
print(loaded.ps)
```

#Session Info
```{r}
sessionInfo()
```

